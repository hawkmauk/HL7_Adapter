# Day Three: Diagrams, the GitHub CI Agent, and a Proper Git Workflow

*HL7 Adapter build log — 19 Feb 2026*

---

Day three started with a concrete goal: **get some diagrams generated automatically** to go alongside the document views. Our ConOps, EICD, gateway signoff, and the rest are already coming out of the model as LaTeX → PDF/HTML, but the views are mostly tables and text. Adding diagrams (even simple ones) would make the docs much easier to scan and would prove that the pipeline can drive more than prose. Getting that into CI meant getting my **GitHub CI agent** to do real work—and I’ve only just started using it.

I’ll be honest: I’ve still been using **ChatGPT outside of Cursor** for a lot of “how do I…?” and “why did this workflow fail?” questions. I’m not sure why; I just prefer asking those questions there rather than using the Cursor feature. Maybe it’s habit, or the sense that CI/YAML is a separate kind of task. Either way, day three was the day I finally leaned on the **GitHub CI/CD Expert** agent (`agent/github_cicd.prompt`) to design and refine the workflows. Its job is to help with GitHub Actions: triggers, jobs, artifacts, caching, and the repo’s conventions (e.g. `python -m ci.generators`, `out/*.tex`, the existing build-docs and release-docs patterns). So I pointed it at “I need to run a diagram step as part of the doc build” and at the current workflow files; it helped get the pipeline to a place where the diagram generation runs in CI and the outputs line up with the rest of the doc artifacts. Still a work in progress, but the agent is now part of the loop.

Once the CI for this is in good shape, I’ve decided to **change how I use git**. So far it’s been mostly direct commits to `main`. That’s fine for a solo spike, but if we want releases, review, and a clearer history, we need **branches and a proper workflow**. So the plan is: feature branches, PRs into `main`, and a release flow that doesn’t rely on “push to main and hope.” To support that, I want to try something more ambitious: **get the Product Owner agent to connect to GitHub and create a roadmap with issues**.

We already have a **Product Owner** agent (`agent/product_owner.prompt`). It’s set up to clarify goals, write user stories and acceptance criteria, and keep the backlog aligned with the MDA lifecycle (CIM → PIM → PSM) and with our document set (SNRS, ConOps, gateway signoff, etc.). What it doesn’t do yet is *talk to GitHub*—create issues, label them, or turn a roadmap into a real backlog in the repo. So the next step is to see whether we can give it that capability: either by having it output structured issue descriptions and labels that I (or a script) can push via the GitHub API, or by wiring it into an action or bot that creates issues from its output. If that works, we’ll have a product owner that doesn’t just draft stories in a vacuum but helps populate the actual board. That’s the experiment.

I’ve also decided how to use the rest of the time. **Two days are behind us** (bootstrapping: MDA library, agents, doc pipeline, CI). The **next two days** I’m going to focus on **architecture**—deepening the CIM and PIM, getting the logical design and interfaces right, and making sure the model is in good shape before we touch deployment. The **final two days** will be about **deployment**: getting the adapter runnable, packaged, and (if we get there) deployable in a realistic way. So: bootstrap done, then architecture, then deployment.

So day three in short: **diagrams in the pipeline**, **GitHub CI agent in use**, **branch-based workflow planned**, and **Product Owner → GitHub roadmap/issues** as the next thing to try. And yes—I still ask a lot of questions outside Cursor. Maybe that’ll shift as the agents get more of the context; for now it’s just how I’m working.

---

## Day three round-up

By end of day three the picture looks like this. The **Product Owner** has planned **27 issues** that take us through to a full implementation, with milestones for delivery. **3 of those are already completed.** So we have a real backlog and a path; the rest is execution.

Some of the issues didn’t pass at first because the **generated documentation** didn’t yet contain everything the acceptance criteria asked for—for example **use cases** in the right place or format. Fixing that (extending the generator or the views so the docs satisfy the criteria) took up a chunk of day three that could otherwise have gone into the model itself. I decided it was worth it: having the docs match what the Product Owner expects will help further down the line, and it keeps us honest about “done.” So I persisted and **obeyed the Product Owner**—even when it cost time.

I also had to do **some tasks manually** that I’d have liked the agents to handle. Creating the **event workflow** in the model was one: the agents weren’t able to get it right, so I did it by hand. That slowed progress too. A big part of the problem is **SysML v2 being new**—there isn’t much content on the web yet, so the models have less to train on and fewer examples to copy. When the spec or the syntax is niche, the agents hit their limits and you fall back to manual work. Something to factor in when planning. As the project grows, that should improve: the LLM will have **more context** from our own models, views, and examples to work with, so the same agents ought to get better at producing and refining SysML v2 as the codebase becomes the reference.

Progress on day three has been **slower than I’d have liked**—there was quite a bit of **manual work** around creating **messages and actions** in the CIM. That’s mainly because I hadn’t done much with actions before, or any work with messages; it’s been a **really worthwhile learning experience**. I’ve also decided to **primarily use an event-driven architecture** so that it’s easier to take a **serverless** approach to implementation if we need to. That choice is now reflected in the model and should set us up well for the deployment phase.

I’ve added a **reviewer agent** to help with writing dev reviews—checking that changes are scoped to the issue, that conventions are followed, and that the diff makes sense before opening a PR. I’m still doing the reviews themselves manually; the agent assists with the write-up and the checklist. Over time I’d like to lean on it more so that “dev review” is less ad hoc.

We’ve also put in place a **Software Development Lifecycle** (see [Software_Development_Lifecycle.md](../Software_Development_Lifecycle.md)). It spells out the per-issue flow: take ownership of a GitHub issue, start from `dev`, create a feature branch, implement, run a dev review (tests, linters, generators, self-review), push, open a PR into `dev`, resolve feedback and conflicts, then merge and close the issue. For milestone completion it defines how we create a release tag on `dev`, open a PR from `dev` to `main`, resolve conflicts, and merge so that CI/CD and release artifacts run on `main`. So we’re no longer “commit to main and hope”—we have a defined path from issue to release.

I’m **pleased with what we have**: backlog, SDLC, reviewer support, diagrams in the pipeline, and the architecture/deployment plan for the next four days. I’m also **slightly concerned about deadlines**. The aim is to have the **models implemented by the end of today** (day three), so that the next two days can focus on architecture in depth and the final two on deployment. We’ll see whether we land there; if not, we’ll adjust. Either way, day three closed with a clear backlog, a written lifecycle, and a realistic view of what’s left.
